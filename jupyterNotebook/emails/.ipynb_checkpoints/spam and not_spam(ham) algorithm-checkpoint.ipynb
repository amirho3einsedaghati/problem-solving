{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "251e1d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [message, class]\n",
       "Index: []"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "import numpy\n",
    "from pandas import DataFrame\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def readFile(path):\n",
    "    for root, dirNames, fileNames in os.walk(path):\n",
    "        for file in fileNames:\n",
    "            pathFile= os.path.join(root, file)\n",
    "            in_body= False\n",
    "            bodyLines= []\n",
    "            \n",
    "            openedFile= io.open(pathFile, 'r', encoding='latin1')\n",
    "            for line in openedFile:\n",
    "                if in_body:\n",
    "                    bodyLines.append(line)\n",
    "                elif line == '\\n':\n",
    "                    in_body= True\n",
    "                \n",
    "            openedFile.close()\n",
    "            message= '\\n'.join(bodyLines)\n",
    "            yield pathFile, message\n",
    "\n",
    "            \n",
    "def fileDataInDirectory(path, classification):\n",
    "    rows= []\n",
    "    index= []\n",
    "    for pathFile, message in readFile(path):\n",
    "        rows.append({'message': message, 'class': classification})\n",
    "        index.append(pathFile)\n",
    "    \n",
    "    return DataFrame(rows, index= index)\n",
    "\n",
    "# class contains spam and not_spam(ham) data  \n",
    "df= DataFrame({'message': [], 'class': []})\n",
    "df= df.append(fileDataInDirectory('E:/my_github_repositories/problem-solving/jupyter notebook/spam', 'spam'))\n",
    "df= df.append(fileDataInDirectory('E:/my_github_repositories/problem-solving/jupyter notebook/not_spam', 'not_spam'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ead0a3e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer= CountVectorizer()\n",
    "counts= vectorizer.fit_transform(df['message'].values) # scale\n",
    "# print(counts)\n",
    "targets= df['class'].values\n",
    "# print(targets)\n",
    "\n",
    "classifier= MultinomialNB()\n",
    "classifier.fit(counts, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e609569b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 27977)\t1\n",
      "  (1, 11302)\t1\n",
      "  (1, 28711)\t1\n",
      "  (1, 60793)\t1\n",
      "  (2, 25116)\t1\n",
      "  (2, 39398)\t1\n",
      "  (2, 39611)\t1\n",
      "  (2, 40533)\t1\n",
      "['not_spam' 'not_spam' 'not_spam']\n"
     ]
    }
   ],
   "source": [
    "example= ['hello','how are you?','free no ok now']\n",
    "example_counts= vectorizer.transform(example)\n",
    "print(example_counts)\n",
    "example_prediction= classifier.predict(example_counts)\n",
    "print(example_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "50b67cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 27977)\t1\n",
      "  (1, 11302)\t1\n",
      "  (1, 28711)\t1\n",
      "  (1, 60793)\t1\n",
      "  (2, 16881)\t1\n",
      "  (2, 25116)\t1\n",
      "  (2, 39398)\t1\n",
      "  (2, 39611)\t1\n",
      "  (2, 59298)\t1\n",
      "['not_spam' 'not_spam' 'not_spam']\n"
     ]
    }
   ],
   "source": [
    "example= ['hello','how are you?','free no frei now www.amir.com']\n",
    "example_counts= vectorizer.transform(example)\n",
    "print(example_counts)\n",
    "example_prediction= classifier.predict(example_counts)\n",
    "print(example_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "12072f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 27977)\t1\n",
      "  (1, 11302)\t1\n",
      "  (1, 28711)\t1\n",
      "  (1, 60793)\t1\n",
      "  (2, 25116)\t2\n",
      "  (2, 39611)\t2\n",
      "['not_spam' 'not_spam' 'not_spam']\n"
     ]
    }
   ],
   "source": [
    "example= ['hello','how are you?','free now, free now']\n",
    "example_counts= vectorizer.transform(example)\n",
    "print(example_counts)\n",
    "example_prediction= classifier.predict(example_counts)\n",
    "print(example_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5d76403b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 27977)\t1\n",
      "  (1, 11302)\t1\n",
      "  (1, 28711)\t1\n",
      "  (1, 60793)\t1\n",
      "  (2, 25116)\t3\n",
      "  (2, 39611)\t3\n",
      "['not_spam' 'not_spam' 'not_spam']\n"
     ]
    }
   ],
   "source": [
    "example= ['hello','how are you?','free now free now free now']\n",
    "example_counts= vectorizer.transform(example)\n",
    "print(example_counts)\n",
    "example_prediction= classifier.predict(example_counts)\n",
    "print(example_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1d17aeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 27977)\t1\n",
      "  (1, 11302)\t1\n",
      "  (1, 28711)\t1\n",
      "  (1, 60793)\t1\n",
      "  (2, 25116)\t4\n",
      "  (2, 39611)\t4\n",
      "['not_spam' 'not_spam' 'spam']\n"
     ]
    }
   ],
   "source": [
    "example= ['hello','how are you?','free now free now free now free now']\n",
    "example_counts= vectorizer.transform(example)\n",
    "print(example_counts)\n",
    "example_prediction= classifier.predict(example_counts)\n",
    "print(example_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebba63b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
